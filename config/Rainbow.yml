experiment: MinigridRainbow
agent: rainbow
policy: 
  name: agents.DQN.Rainbow
  device: cuda
  settings:
    atoms:
    V_min:
    V_max:
    discount:
    norm_clip:
    history_length: 1
    architecture:
    hidden_size:
    noisy_std:
    multi_step:
    # model: 

train:
  data_collection_steps: 3000
  train_steps: 500000
  max_episode_steps: 200
  nb_eval_episodes: 150
  eval_frequency: 20000
  seed: 100
  save_tensorboard: true
  log_frequency: 5000
  reward_clip:

env:
  name:
  settings:

memory:
  name: utils.memory.ReplayMemory
  settings:
    capacity: 100000
    device: cuda
    history_length:
    discount: 0.9
    multi_step:
    priority_weight:
    priority_exponent:


logger:
  eval episode performance:
    - step